---
title: "Introduction to Bayesian Marginal Additive Models"
author: "Tianyi Pan"
date: "`r Sys.Date()`"
output: 
  pdf_document:
    toc: TRUE
    toc_depth: 3
  html_document:
    toc: true
    toc_float:
      collapsed: false
      smooth_scroll: true
    toc_depth: 3
bibliography: bibfile.bib  
vignette: >
  %\VignetteIndexEntry{Introduction to Bayesian Marginal Additive Models}
  %\VignetteEncoding{UTF-8}
  %\VignetteEngine{knitr::rmarkdown}
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  cache = TRUE,
  fig.width = 5,
  fig.height = 3.5, 
  fig.align ='center'
)
knitr::opts_knit$set(root.dir = "/Users/pantianyi/Documents/Research/Bayesian MAM/BMAM")
```

```{r include=FALSE}
## source code
source("R/bmam.R")
source("R/conditional_brms.R")
source("R/generate_pred.R")
source("R/plot.bmam.R")
source("R/summary.R")
source("R/SimData.R")
```

In this document, we illustrate R functions for Bayesian marginal
additive models (BMAM).

## Brief overview of Bayesian marginal additive models

@heagerty2000marginalized presented the marginal models in which the
marginal mean, rather than the conditional mean given random effects, is
regressed on covariates. Marginal models are useful when we are
interested in associations averaged across a population of clusters. If
the covariate-outcome association is unknown, we could use additive
models to measure the potentially non-linear relationships.
@mcgee2022flexible proposed a marginal additive model (MAM) for modeling
dependent data with non-linear population-averaged associations.

We propose a Bayesian marginal additive model (BMAM) extending the
marginal additive model (MAM) into a Bayesian context.

### Bayesian conditional models

We consider a Generalized Additive Mixed Model (GAMM), $$
g\left\{\mu^{\mathrm{C}}\left(\boldsymbol{x}_{i j}, \boldsymbol{z}_{i j} \mid \boldsymbol{u}_{i}\right)\right\}=\sum_{l=1}^{p} f_{l}^{\mathrm{C}}\left(x_{i j l}\right)+\boldsymbol{z}_{i j}^{\mathrm{T}} \boldsymbol{u}_{i}
$$ where $i = 1,\cdots,N$ indexes clusters and $j = 1, \cdots, n_i$
indexes units within clusters. Random effects $\boldsymbol{u}_{i}$
follow a normal distribution with mean 0 and covariance matrix
$\boldsymbol{\Sigma}=\boldsymbol{\Lambda}\left(\boldsymbol{\sigma}\right) \boldsymbol{\Omega} \boldsymbol{\Lambda}\left(\boldsymbol{\sigma}\right)$,
where $\boldsymbol{\Lambda}\left(\boldsymbol{\sigma}\right)$ denotes the diagonal matrix with diagonal elements $\boldsymbol{\sigma}$.

$f_{l}^{\mathrm{C}}(x)=\sum_{q=1}^{d_{l}} b_{l q}^{\mathrm{C}}(x) \alpha_{l q}^{\mathrm{C}}$
are unknown smooth functions. Each
$\boldsymbol{\alpha}_{l}^{\mathrm{C}}$ is associated with a penalty
$\mathcal{P}_{\tau_{l}^{\mathrm{C}}}\left(\boldsymbol{\alpha}_{l}^{\mathrm{C}} ; \boldsymbol{S}_{l}\right) \propto \mathrm{exp} \left( - \tau_{l} \boldsymbol{\alpha}_{l}^{\mathrm{C}^\mathrm{T}} \boldsymbol{S}_{l} \boldsymbol{\alpha}_{l}^{\mathrm{C}} \right)$.

According to @wood2006generalized,
$\sum_{q=1}^{d_{l}} b_{l q}^{\mathrm{C}}(x) \alpha_{l q}^{\mathrm{C}}$
can be written as
$\sum_{q=1}^{d_{l}} b_{l q}^{*\mathrm{C}}(x) \alpha_{l q}^{*\mathrm{C}}$.
Then the penalty can be termed as a prior distribution, $$
\alpha_{l k}^{*\mathrm{C}} \sim \mathrm{N}(0,\frac{1}{\tau_{l}}), k=3,\cdots,d_{l},
$$ where
$\left[ b_{l 1}^{*\mathrm{C}}(x), b_{l 2}^{*\mathrm{C}}(x), \cdots, b_{l d_{l}}^{*\mathrm{C}}(x)\right] = \left[ b_{l 1}^{\mathrm{C}}(x), b_{l 2}^{\mathrm{C}}(x), \cdots, b_{l d_{l}}^{\mathrm{C}}(x)\right] \mathbf{D}_{l+}^{-1}$,
$\mathbf{D}_{l+} = \left[\begin{array}{cc} \mathbf{I}_{2} \  \ \mathbf{0} \\ \mathbf{D}_l \end{array}\right]$.
and $\mathbf{D}_l$ is a $(d_{l}-2)\times d_{l}$ matrix with
$\mathbf{D}_l^\mathrm{T} \mathbf{D}_l = S_l$

Thus, the GAMM can be rewritten as,

$$
\begin{aligned}
g\left\{\mu^{\mathrm{C}}\left(\boldsymbol{x}_{i j}, \boldsymbol{z}_{i j} \mid \boldsymbol{u}_{i}\right)\right\}&=\sum_{l=1}^{p} \sum_{q=1}^{d_{l}} b_{l q}^{*\mathrm{C}}(x) \alpha_{l q}^{*\mathrm{C}}+\boldsymbol{z}_{i j}^{\mathrm{T}} \boldsymbol{u}_{i},\\
\boldsymbol{u}_{i} &\sim \mathrm{N}(0,\boldsymbol{\Lambda}\left(\boldsymbol{\sigma}\right) \boldsymbol{\Omega} \boldsymbol{\Lambda}\left(\boldsymbol{\sigma}\right)),\\
\alpha_{l k}^{*\mathrm{C}} &\sim \mathrm{N}(0,\frac{1}{\tau_{l}}), k=3,\cdots,d_{l}. 
\end{aligned}
$$ 
Besides the two parameters $\boldsymbol{u}_{i}$ and
$\alpha_{l k}^{*\mathrm{C}},k=3,\cdots,d_{l}$, in a Bayesian model, we
need to assign prior distributions for
$\alpha_{l 1}^{*\mathrm{C}},\alpha_{l 2}^{*\mathrm{C}}$, $\tau_l$,
$\boldsymbol{\sigma}$ and $\boldsymbol{\Omega}$.

Our `bmam` functions are built on `brms` package. The prior
distributions can be set in `brms` function. By default,
$\alpha_{l 1}^{*\mathrm{C}},\alpha_{l 2}^{*\mathrm{C}}$ have an improper
flat prior, and $\sqrt{1/\tau_l}$, the standard deviation in prior
distribution of $\boldsymbol{u}_{i}$, has a half student-t prior with 3
degree of freedom. The prior distribution of $\boldsymbol{\sigma}$ is
also half student-t prior with 3 degree of freedom, and
$\Omega \sim \operatorname{LKJ}(1)$.

### Bayesian marginal additive models

The Bayesian marginal additive model (BMAM) is, $$
g\left\{\mu^{\mathrm{M}}\left(\boldsymbol{x}_{i j}\right)\right\}=f^{\mathrm{M}}\left(\boldsymbol{x}_{i j}\right)
$$ where
$f^{\mathrm{M}}\left(\boldsymbol{x}_{i j}\right) = \sum_{l=1}^{p} f_{l}^{\mathrm{M}}\left(x_{i j l}\right) = \sum_{l=1}^{p}\sum_{q=1}^{Q_{l}} b_{l q}^{\mathrm{M}}(x) \alpha_{l q}^{\mathrm{M}}$.
The inference on parameters $\alpha_{l q}^{\mathrm{M}}$ is based on the
Bayesian conditional model through post-hoc marginalization
[@hedeker2018note]. More details about the relationship between marginal
additive models and conditional models can be found in
@mcgee2022flexible.

In practice, we could draw the posterior samples in conditional models. For each posterior sample, an estimate of
$\alpha_{lq}^{\mathrm{M}}$ could be calculated. Assuming $H$ samples are
drawn from posterior distribution in a conditional model, we could
obtain $H$ estimates of $\alpha_{lq}^{\mathrm{M}}$, and then make an
inference on $\alpha_{lq}^{\mathrm{M}}$.

## Basic example of Bayesian marginal additive models

We use the function `SimData` to generate some data, to illustrate the
main features of our R functions for BMAM. The data are generated
according to the set-up in @mcgee2022flexible. We consider the binary
case, where the outcome variable $Y$ follows a Bernoulli distribution.
The link function $g(\cdot)$ is set as the logit function.

We generate three covariates
$\boldsymbol{x}_{i j}=\left(x_{i j 1}, x_{i j 2}, x_{i j 3}\right)^{\mathrm{T}}$
where $x_{i j p} \sim \operatorname{Unif}(-1,1)$ for $p=1,2,3$. After
assuming the forms of smooth functions $f_{1}^{\mathrm{M}}(\cdot)$ and
$f_{2}^{\mathrm{M}}(\cdot)$, we could generate $Y_{ij}$ according to the
marginal model, 

$$
\operatorname{logit}\left\{\mu^{\mathrm{M}}\left(\boldsymbol{x}_{i j}\right)\right\}=f_{1}^{\mathrm{M}}\left(x_{i j 1}\right)+f_{2}^{\mathrm{M}}\left(x_{i j 2}\right)+\beta_{3} \cdot x_{i j 3}.
$$ 
In addition, we have the following random intercepts and slopes
dependence structure,


$$
\begin{aligned}
\operatorname{logit}\left\{\mu^{\mathrm{C}}\left(\boldsymbol{x}_{i j} \mid u_{i}\right)\right\} &=\Delta\left(\boldsymbol{x}_{i j}\right)+u_{i 0}+u_{i 1} \cdot x_{i j 3} \\
{\left[\begin{array}{l}
u_{i 0} \\
u_{i 1}
\end{array}\right] } & \sim M V N\left(\left[\begin{array}{l}
0 \\
0
\end{array}\right],\left[\begin{array}{cc}
4 & 1 \\
1 & 1
\end{array}\right]\right)
\end{aligned}
$$


Here we set $\beta_3 = 0$, the number of cluster $N = 100$ and the
number of units within clusters
$n_i = 10, i = 1, \ldots, N$.

```{r}
set.seed(4321)
simdata <- SimData(K = 100, Nk = 10)
dat <- simdata$data
fun <- simdata$f

knitr::kable(head(dat), digits = 4)
```

where `simdata$data` is the generated dataset and `simdata$f` is the
smooth functions $f_{1}^{\mathrm{M}}(\cdot)$ and
$f_{2}^{\mathrm{M}}(\cdot)$.

```{r fig.height=3.5, fig.show='hold', fig.width=6}
x = seq(-1,1,length=1000)
f1 <- fun[[1]](x)
f2 <- fun[[2]](x)
par(mfrow = c(1,2))
plot(x, f1, type = "l")
plot(x, f2, type = "l")
```

```{r include=FALSE}
par(mfrow = c(1,1))
```

### Fit BMAM

The BMAM is based on Bayesian GAMM, which could fitted by `brm` function
in `brms` package.

```{r message=FALSE, warning=FALSE}
library(brms)
model_brms <- brm(bf(y ~  x3 + s(x1) + s(x2) + (1+x3|id)),
                  data = dat, family = "bernoulli", 
                  cores = 4, seed = 4321,
                  warmup = 1000, iter = 2000, chains = 4, 
                  refresh=0, backend = "cmdstanr")
```

The setting of `brm` function can be found in @burkner2017brms. We use
`bf()` to specify a formula containing smooth terms and random effects.
The GAMM is specified as a logistic model and we sample 4 chains with
2000 iterations (the first 1000 iterations are warm-up). It should be noted
that our `BMAM` functions only support the [`cmdstanr`
backend](https://mc-stan.org/cmdstanr/).

Then, we draw the trace plots to check the convergence in Hamiltonian
Monte Carlo in `brms` and the density plots of the posterior samples.

```{r fig.width = 5, fig.height = 7}
plot(model_brms)
```

`BMAM` functions are built on `brmsmargins` package. We firstly load the
dependent packages,

```{r message=FALSE, warning=FALSE}
library(brmsmargins)
library(data.table)
library(dplyr)
library(ggplot2)
```

To fit the BMAM, we use the `bmam` function.

```{r}
bmam.fit <- bmam(object = model_brms, k=100, CIType="ETI", CI = 0.95)
```

Monte Carlo method is used to integrate out the random
effects, and we set the random draws as `k = 100` (default). The type of
credible intervals (CI) can be specified by `CIType`. In this example,
we use Equal-Tailed Interval, ETI (default). Please see
[here](https://easystats.github.io/bayestestR/reference/ci.html) for
more `CIType` options supported in this function. The probability of CI is chosen as 95%.

### Summarize model

Let's now summarize the fitted BMAM. 

The `summary` function will return
a list of data frames. Each data frame contains the summary of posterior
distribution of the coefficients in linear terms, e.g. Intercept and $X_3$ in this example. 

The first dataframe is for the estimates in marginal model (BMAM), and the second is for the estimates in conditional model (Bayesian GAMM).
```{r}
bmam.summary <- summary(bmam.fit)
```

For each parameter, the returned information include,

-   M: the mean of the posterior samples
-   Mdn: the median of the posterior samples
-   LL: the lower limit of the credible interval
-   UL: the upper limit of the credible interval
-   CI: the probability of credible interval
-   CIType: the type of credible interval


If we are also interested in the smooth functions, we can set `plot_smooth` as `TRUE` to plot the estimated smooth functions, 
```{r}
bmam.summary <- summary(bmam.fit, plot_smooth = TRUE)
```

In the figures, we demontrate the point estimates (mean of the posterior samples) and 95% CI (ETI). The red one denotes the estimates from BMAM. The blue one denotes the estimates from Bayesian GAMM (conditional model).

The results from `summary` function also provide the summary of coefficients in smooth terms $\alpha_l^{\mathrm{M}}$ in BMAM and smooth terms $\alpha_l^{\mathrm{C}}$ in Bayesian GAM.

The default dimension of coefficients $\alpha_l^{\mathrm{M}}$ (or $\alpha_l^{\mathrm{C}}$) is 10, i.e. $Q_{1} = Q_{2} = 10$ in this example. The first parameter $\alpha_{l 1}^{\mathrm{M}}$ (or $\alpha_{l 1}^{\mathrm{C}}$) is the intercept, and we only report the
coefficients $\alpha_{l q}^{\mathrm{M}}, \alpha_{l q}^{\mathrm{C}}, q=2,3,\cdots,Q_l$.

The coefficients in smooth terms in BMAM,
```{r}
knitr::kable(bmam.summary$BMAM$Smooth[[1]], digits = 4)
knitr::kable(bmam.summary$BMAM$Smooth[[2]], digits = 4)
```

The coefficients in smooth terms in Bayesian GAMM (conditional model),
```{r}
knitr::kable(bmam.summary$Conditional_Model$Smooth[[1]], digits = 4)
knitr::kable(bmam.summary$Conditional_Model$Smooth[[2]], digits = 4)
```





### Visualize model

Beside the figures from `summary` function, we also provide a `plot` function to visualize the estimated smooth
functions.

The `bmam` function will call the built-in function `generate_pred` to
generate the predicted data to illustrate the estimated smooth
functions. The predicted data are generated according to the model and
the data for model fitting. In this example, we use the simulated data
`simdata$data` to fit the model
`bf(y ~  x3 + s(x1) + s(x2) + (1+x3|id))`. The function will generate a
sequence with length 100 (default) from the minimum value of `x1` to
the maximum value of `x1` in `simdata$data` and a sequence with length is 100 (default) from the minimum value of `x2` to the maximum value of `x2` in `simdata$data`. The length of sequence can be set as the other values by  argument `length`, for example,

```{r eval=FALSE}
bmam(object = model_brms, k=100, CIType="ETI", CI = 0.95,
     length = 200)
```

In addition, users can also provide a predicted data, for example,

```{r eval=FALSE}
bmam(object = model_brms, k=100, CIType="ETI", CI = 0.95,
     preddat = user.preddat)
```

The `plot` function will show the plots of the estimated smooth functions in BMAM and the conditional model (Bayesian GAMM). If users want to plot the BMAM only, please add an argument `conditional = FALSE`. 
```{r}
plot(bmam.fit)
```


We could also provide the true forms of smooth functions `simdata$f` to the `plot` function to compare the fitted values and true values,

```{r}
plot(bmam.fit, smooth.function = simdata$f)
```

### Compare with other models

The argument `compared.model` in `plot` function allows us to provide
the other models compared with BMAM and the conditional model.

The supported models include

-   Marginal additive models by `mam` package
-   Generalized additive models by `mgcv` package
-   Bayesian generalized additive models by `brms` package

#### Marginal additive models

The frequentist marginal additive model can be fitted by `mam` function
in `mam` package [@mcgee2022flexible]. The predicted data in the `mam`
should be the same as that we used in `bmam`. We can obtain the generated
predicted data from the fitted `bmam` object by `bmam.fit$Preddat`.

```{r message=FALSE, warning=FALSE}
library(mam)
library(mgcv)
```

```{r message=FALSE, warning=FALSE}
themam <- mam(smooth = list(s(x1),s(x2)),
                   re = y ~ (1+x3|id),
                   fe = ~ x3,
                   dat = dat,
                   margdat = dat,
                   preddat = bmam.fit$Preddat,
                   control = mam_control(
                     method = 'trust',
                     varmethod = 1,
                     verbose = FALSE,
                     retcond = TRUE))
```

```{r}
plot(bmam.fit, compared.model = themam, smooth.function = simdata$f)
```

#### Generalized additive models

We could also compare the the models with GAM. The `plot` function now supports
the generalized additive models by `mgcv` package and Bayesian
generalized additive models by `brms` package.

```{r}
gam <- gam(y ~  x3 + s(x1) + s(x2),
           data=dat,family=binomial(),method="REML")
```

```{r}
plot(bmam.fit, compared.model = gam, smooth.function = simdata$f)
```

```{r message=FALSE, warning=FALSE}
bgam <- brm(bf(y ~  x3 + s(x1) + s(x2)), data = dat, 
            family = "bernoulli", 
            cores = 4, seed = 4321, warmup = 1000, 
            iter = 2000, chains = 4,
            refresh=0, backend = "cmdstanr")
```

```{r}
plot(bmam.fit, compared.model = bgam, smooth.function = simdata$f)
```

### Center the smooth terms  
In some cases, we may want to center the smooth functions. 

We could add an argument `centered = TRUE` in `bmam` function, to estimate the centered smooth functions. 


```{r}
bmam.fit.centered <- bmam(object = model_brms, k=100, CIType="ETI", CI = 0.95, centered = TRUE)
```

We can also fit a MAM with centered smooth functions, 
```{r message=FALSE, warning=FALSE}
themam.centered <- mam(smooth = list(s(x1),s(x2)),
                   re = y ~ (1+x3|id),
                   fe = ~ x3,
                   dat = dat,
                   margdat = dat,
                   preddat = bmam.fit.centered$Preddat,
                   control = mam_control(
                     centered = TRUE,
                     method = 'trust',
                     varmethod = 1,
                     verbose = FALSE,
                     retcond = TRUE))
```
Then, we can draw the plots by `plot` function introduced above to compare the centered smooth terms in BMAM, the conditional model and MAM. 
```{r}
plot(bmam.fit.centered, compared.model = themam.centered)
```


## References
